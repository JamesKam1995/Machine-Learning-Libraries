{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 64, 128, 128])\n",
      "Output shape: torch.Size([32, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from squeezenet import FireModule\n",
    "\n",
    "# Define model parameters\n",
    "in_channels = 64\n",
    "squeeze_channels = 16\n",
    "expansionX1_channels = 64\n",
    "expansionX3_channels = 64\n",
    "batch_size = 32\n",
    "height, width = 128, 128\n",
    "\n",
    "# Create a random input tensor\n",
    "x = torch.randn(batch_size, in_channels, height, width)\n",
    "\n",
    "# Initialize the FireModule\n",
    "fire_module = FireModule(in_channels, squeeze_channels, expansionX1_channels, expansionX3_channels)\n",
    "\n",
    "# Forward pass\n",
    "output = fire_module(x)\n",
    "\n",
    "# Check the output shape\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 111, 111]          14,208\n",
      "              ReLU-2         [-1, 96, 111, 111]               0\n",
      "         MaxPool2d-3           [-1, 96, 55, 55]               0\n",
      "            Conv2d-4           [-1, 16, 55, 55]           1,552\n",
      "              ReLU-5           [-1, 16, 55, 55]               0\n",
      "            Conv2d-6           [-1, 64, 55, 55]           1,088\n",
      "              ReLU-7           [-1, 64, 55, 55]               0\n",
      "            Conv2d-8           [-1, 64, 55, 55]           9,280\n",
      "              ReLU-9           [-1, 64, 55, 55]               0\n",
      "       FireModule-10          [-1, 128, 55, 55]               0\n",
      "           Conv2d-11           [-1, 16, 55, 55]           2,064\n",
      "             ReLU-12           [-1, 16, 55, 55]               0\n",
      "           Conv2d-13           [-1, 64, 55, 55]           1,088\n",
      "             ReLU-14           [-1, 64, 55, 55]               0\n",
      "           Conv2d-15           [-1, 64, 55, 55]           9,280\n",
      "             ReLU-16           [-1, 64, 55, 55]               0\n",
      "       FireModule-17          [-1, 128, 55, 55]               0\n",
      "           Conv2d-18           [-1, 32, 55, 55]           4,128\n",
      "             ReLU-19           [-1, 32, 55, 55]               0\n",
      "           Conv2d-20          [-1, 128, 55, 55]           4,224\n",
      "             ReLU-21          [-1, 128, 55, 55]               0\n",
      "           Conv2d-22          [-1, 128, 55, 55]          36,992\n",
      "             ReLU-23          [-1, 128, 55, 55]               0\n",
      "       FireModule-24          [-1, 256, 55, 55]               0\n",
      "        MaxPool2d-25          [-1, 256, 27, 27]               0\n",
      "           Conv2d-26           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-27           [-1, 32, 27, 27]               0\n",
      "           Conv2d-28          [-1, 128, 27, 27]           4,224\n",
      "             ReLU-29          [-1, 128, 27, 27]               0\n",
      "           Conv2d-30          [-1, 128, 27, 27]          36,992\n",
      "             ReLU-31          [-1, 128, 27, 27]               0\n",
      "       FireModule-32          [-1, 256, 27, 27]               0\n",
      "           Conv2d-33           [-1, 48, 27, 27]          12,336\n",
      "             ReLU-34           [-1, 48, 27, 27]               0\n",
      "           Conv2d-35          [-1, 192, 27, 27]           9,408\n",
      "             ReLU-36          [-1, 192, 27, 27]               0\n",
      "           Conv2d-37          [-1, 192, 27, 27]          83,136\n",
      "             ReLU-38          [-1, 192, 27, 27]               0\n",
      "       FireModule-39          [-1, 384, 27, 27]               0\n",
      "           Conv2d-40           [-1, 48, 27, 27]          18,480\n",
      "             ReLU-41           [-1, 48, 27, 27]               0\n",
      "           Conv2d-42          [-1, 192, 27, 27]           9,408\n",
      "             ReLU-43          [-1, 192, 27, 27]               0\n",
      "           Conv2d-44          [-1, 192, 27, 27]          83,136\n",
      "             ReLU-45          [-1, 192, 27, 27]               0\n",
      "       FireModule-46          [-1, 384, 27, 27]               0\n",
      "           Conv2d-47           [-1, 64, 27, 27]          24,640\n",
      "             ReLU-48           [-1, 64, 27, 27]               0\n",
      "           Conv2d-49          [-1, 256, 27, 27]          16,640\n",
      "             ReLU-50          [-1, 256, 27, 27]               0\n",
      "           Conv2d-51          [-1, 256, 27, 27]         147,712\n",
      "             ReLU-52          [-1, 256, 27, 27]               0\n",
      "       FireModule-53          [-1, 512, 27, 27]               0\n",
      "        MaxPool2d-54          [-1, 512, 13, 13]               0\n",
      "           Conv2d-55           [-1, 64, 13, 13]          32,832\n",
      "             ReLU-56           [-1, 64, 13, 13]               0\n",
      "           Conv2d-57          [-1, 256, 13, 13]          16,640\n",
      "             ReLU-58          [-1, 256, 13, 13]               0\n",
      "           Conv2d-59          [-1, 256, 13, 13]         147,712\n",
      "             ReLU-60          [-1, 256, 13, 13]               0\n",
      "       FireModule-61          [-1, 512, 13, 13]               0\n",
      "          Dropout-62          [-1, 512, 13, 13]               0\n",
      "           Conv2d-63         [-1, 1000, 13, 13]         513,000\n",
      "AdaptiveAvgPool2d-64           [-1, 1000, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,248,424\n",
      "Trainable params: 1,248,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 92.62\n",
      "Params size (MB): 4.76\n",
      "Estimated Total Size (MB): 97.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "from squeezenet import SqueezeNet\n",
    "\n",
    "# Create a SqueezeNet model\n",
    "model = SqueezeNet(in_channels=3, num_classes=1000)\n",
    "\n",
    "# Generate model summary\n",
    "summary(model, input_size=(3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transformations for the training and test sets\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.RandomCrop(32, padding=4),  # Data augmentation\n",
    "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),  # Normalize\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/391], Loss: 2.3042\n",
      "Epoch [1/10], Step [200/391], Loss: 2.2557\n",
      "Epoch [1/10], Step [300/391], Loss: 2.0154\n",
      "Epoch [2/10], Step [100/391], Loss: 1.9102\n",
      "Epoch [2/10], Step [200/391], Loss: 1.8826\n",
      "Epoch [2/10], Step [300/391], Loss: 1.8586\n",
      "Epoch [3/10], Step [100/391], Loss: 1.8315\n",
      "Epoch [3/10], Step [200/391], Loss: 1.8290\n",
      "Epoch [3/10], Step [300/391], Loss: 1.7996\n",
      "Epoch [4/10], Step [100/391], Loss: 1.7851\n",
      "Epoch [4/10], Step [200/391], Loss: 1.7724\n",
      "Epoch [4/10], Step [300/391], Loss: 1.7662\n",
      "Epoch [5/10], Step [100/391], Loss: 1.7451\n",
      "Epoch [5/10], Step [200/391], Loss: 1.7011\n",
      "Epoch [5/10], Step [300/391], Loss: 1.6835\n",
      "Epoch [6/10], Step [100/391], Loss: 1.6175\n",
      "Epoch [6/10], Step [200/391], Loss: 1.6150\n",
      "Epoch [6/10], Step [300/391], Loss: 1.5776\n",
      "Epoch [7/10], Step [100/391], Loss: 1.5527\n",
      "Epoch [7/10], Step [200/391], Loss: 1.5341\n",
      "Epoch [7/10], Step [300/391], Loss: 1.5307\n",
      "Epoch [8/10], Step [100/391], Loss: 1.5036\n",
      "Epoch [8/10], Step [200/391], Loss: 1.4750\n",
      "Epoch [8/10], Step [300/391], Loss: 1.4642\n",
      "Epoch [9/10], Step [100/391], Loss: 1.4263\n",
      "Epoch [9/10], Step [200/391], Loss: 1.4085\n",
      "Epoch [9/10], Step [300/391], Loss: 1.4076\n",
      "Epoch [10/10], Step [100/391], Loss: 1.3640\n",
      "Epoch [10/10], Step [200/391], Loss: 1.3672\n",
      "Epoch [10/10], Step [300/391], Loss: 1.3502\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SqueezeNet(in_channels=3, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 50.95%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
